{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Analysis\n",
    "_**HARD: This is a curveball assignment. Plus, this is Python without Pandas.**_\n",
    "\n",
    "#### The objective of this assignment is for you to explain what is happening in each cell in clear, understandable language. \n",
    "\n",
    "#### _There is no need to code._ The code is there for you, and it already runs. Your task is only to explain what each line in each cell does.\n",
    "\n",
    "#### The placeholder cells should describe what happens in the cell below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below imports `os` as a dependency because the `os.path.join` function. Also, the `string` dependency is needed because later in the script, `string.punctuation` will be used to detect and remove punctuation symbols. Explain what the line `from collection import Counter` does.\n",
    "\n",
    "The last line imports the Counter library which will assist the user later when calculating the word counts within the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is accessing a file (resume.md) through the path shown in quotes.\n",
    "\n",
    "The variables are in all caps to differentiate them as variable constants (indicated by all caps) meaning the set values cannot be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "resume_path = os.path.join(\".\", 'resume.md')\n",
    "\n",
    "# Skills to match\n",
    "REQUIRED_SKILLS = {\"excel\", \"python\", \"mysql\", \"statistics\"}\n",
    "DESIRED_SKILLS = {\"r\", \"git\", \"html\", \"css\", \"leaflet\", \"modeling\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below calls a function that defines a local path to read and reformat a file into a list. \n",
    "\n",
    "The .lower changes the file content to lower case. The .split separates content strings into rows (lists) and since a separater is not defined, whitespace will be used as the default. by the hard return in the file . \n",
    "\n",
    "The return functions returns the lines of text that will be read in this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    # Helper function to read a file and return the data.\n",
    "    with open(filepath, \"r\") as resume_file_handler:\n",
    "        resume_contents = resume_file_handler.read()\n",
    "        resume_contents = resume_contents.lower()\n",
    "        resume_tokens = resume_contents.split()\n",
    "        return resume_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates a variable (word_list) that holds the list of resume text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the text for a Resume\n",
    "word_list = load_file(resume_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below reads through each line of the list data and returns unique values into a set. \n",
    "\n",
    "A punctuation set is also created and is later used to remove matches from the \"resume\" set with the line \"resume = resume - punctuation\". (Subtracting \"punctuation\" from \"resume\" removes any matches (punctuation that may have been read in as words) from the resume set.\n",
    "\n",
    "Lastly, a comment line (text string) and the new set are displayed on the terminal. '\\n means a new line will be started to write the text string ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WORDS BEFORE MOVING PUNCTUATION\n",
      "{'sql,', 'front-end', 'mining', 'mongodb', 'big', 'hadoop', 'education', 'sets', 'css,', 'skills', '*', 'advanced', 'statistics,', 'machine', 'git/github', 'javascript,', 'intelligence', 'stein', 'media', 'basic', 'boot', 'apps', 'html,', 'modeling', 'in', 'bootstrap,', 'using', 'web', 'r,', 'learning', 'frank', 'microsoft', 'tableau', 'developing', 'software', 'python', 'working', 'experience', 'vba', 'excel.', 'interactions,', 'visualizations', 'creating', 'mysql', 'business', 'analytics', 'mining,', 'writing', 'visualization', '#', 'graduate', 'with', 'camp', 'data', 'interests', 'performing', 'contributing', 'social', 'leaflet.js', 'python,', 'open-source', 'from', 'cloud', 'learning,', '##', 'forecasting', 'd3,', 'excel,', 'api', 'pandas', 'designing', 'hadoop,', 'to', 'the', 'files', 'and', 'd3', 'tables', 'databases', 'html/css,', 'pivot', 'statistics', 'scripts', 'algorithms', 'apis.', 'analyze', 'n.', 'aws', 'tableau,'}\n",
      "\n",
      "WORDS AFTER MOVING PUNCTUATION\n",
      "{'sql,', 'front-end', 'mining', 'mongodb', 'big', 'hadoop', 'education', 'sets', 'skills', 'css,', 'advanced', 'statistics,', 'machine', 'git/github', 'javascript,', 'intelligence', 'stein', 'media', 'basic', 'boot', 'apps', 'html,', 'modeling', 'in', 'bootstrap,', 'using', 'web', 'r,', 'learning', 'frank', 'tableau', 'microsoft', 'developing', 'software', 'python', 'working', 'experience', 'vba', 'excel.', 'interactions,', 'visualizations', 'creating', 'mysql', 'business', 'analytics', 'mining,', 'writing', 'visualization', 'graduate', 'with', 'camp', 'data', 'interests', 'performing', 'contributing', 'social', 'leaflet.js', 'python,', 'open-source', 'from', 'cloud', 'learning,', '##', 'forecasting', 'd3,', 'excel,', 'api', 'pandas', 'designing', 'hadoop,', 'to', 'the', 'files', 'and', 'd3', 'tables', 'databases', 'html/css,', 'pivot', 'statistics', 'scripts', 'algorithms', 'apis.', 'analyze', 'n.', 'aws', 'tableau,'}\n"
     ]
    }
   ],
   "source": [
    "# Create a set of unique words from the resume\n",
    "resume = set()\n",
    "\n",
    "# HINT: Single elements in a programming language are often referred to as tokens\n",
    "for token in word_list:\n",
    "    resume.add(token)\n",
    "\n",
    "print('\\nWORDS BEFORE MOVING PUNCTUATION')    \n",
    "print(resume)\n",
    "\n",
    "# Remove Punctuation that were read as whole words\n",
    "punctuation = set(string.punctuation)\n",
    "# HINT: Attributes that are in `resume` that are not in `punctuation` (difference)\n",
    "resume = resume - punctuation\n",
    "\n",
    "print('\\nWORDS AFTER MOVING PUNCTUATION')    \n",
    "print(resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below prints matches from the resume set and 'required skills' list and then the same for matches between the resume and 'desired_skills' list.\n",
    "\n",
    "Next, code removes punctuation from the resume data word by word and character by character.\n",
    "\n",
    "Afterwards, the program searches word by word and removes all stop words (words matched with words in the stop_words list).\n",
    "\n",
    "The final word_list data will have no punctuation and no stop words in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUIRED SKILLS\n",
      "{'python', 'mysql', 'statistics'}\n",
      "DESIRED SKILLS\n",
      "{'modeling'}\n",
      "\n",
      "WORD LIST AFTER PUNCTUATION REMOVAL\n",
      "['frank', 'n.', 'stein', '##', 'education', 'data', 'analytics', 'and', 'visualization', 'boot', 'camp', 'graduate', '##', 'experience', 'creating', 'pivot', 'tables', 'and', 'vba', 'scripts', 'in', 'excel.', 'modeling', 'and', 'forecasting', 'data', 'using', 'basic', 'statistics', 'writing', 'python', 'scripts', 'to', 'analyze', 'data', 'sets', 'from', 'files', 'and', 'apis.', 'social', 'media', 'mining', 'using', 'python', 'working', 'with', 'mysql', 'and', 'mongodb', 'databases', 'developing', 'front-end', 'web', 'visualizations', 'using', 'html,', 'css,', 'bootstrap,', 'd3,', 'and', 'leaflet.js', 'using', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'with', 'hadoop', 'working', 'with', 'machine', 'learning', 'algorithms', '##', 'skills', 'microsoft', 'excel,', 'python,', 'javascript,', 'html/css,', 'api', 'interactions,', 'social', 'media', 'mining,', 'sql,', 'hadoop,', 'tableau,', 'advanced', 'statistics,', 'machine', 'learning,', 'r,', 'git/github', '##', 'interests', 'contributing', 'to', 'open-source', 'software', 'data', 'analytics', 'with', 'python', 'and', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'with', 'html,', 'css,', 'javascript,', 'and', 'd3', 'working', 'with', 'big', 'data', 'in', 'the', 'cloud', 'using', 'aws']\n",
      "\n",
      "WORD LIST AFTER CHARACTER PUNCTUATION REMOVAL\n",
      "['frank', 'n', 'stein', '', 'education', 'data', 'analytics', 'and', 'visualization', 'boot', 'camp', 'graduate', '', 'experience', 'creating', 'pivot', 'tables', 'and', 'vba', 'scripts', 'in', 'excel', 'modeling', 'and', 'forecasting', 'data', 'using', 'basic', 'statistics', 'writing', 'python', 'scripts', 'to', 'analyze', 'data', 'sets', 'from', 'files', 'and', 'apis', 'social', 'media', 'mining', 'using', 'python', 'working', 'with', 'mysql', 'and', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'using', 'html', 'css', 'bootstrap', 'd3', 'and', 'leafletjs', 'using', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'with', 'hadoop', 'working', 'with', 'machine', 'learning', 'algorithms', '', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', '', 'interests', 'contributing', 'to', 'opensource', 'software', 'data', 'analytics', 'with', 'python', 'and', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'with', 'html', 'css', 'javascript', 'and', 'd3', 'working', 'with', 'big', 'data', 'in', 'the', 'cloud', 'using', 'aws']\n",
      "\n",
      "WORD LIST AFTER STOP WORDS\n",
      "['frank', 'n', 'stein', '', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', '', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', '', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', '', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Required Skills Match using Set Intersection\n",
    "print('REQUIRED SKILLS')\n",
    "print(resume & REQUIRED_SKILLS)\n",
    "\n",
    "# Calculate the Desired Skills Match using Set Intersection\n",
    "print('DESIRED SKILLS')\n",
    "print(resume & DESIRED_SKILLS)\n",
    "\n",
    "# Word Punctuation Cleaning\n",
    "word_list = [word for word in word_list if word not in string.punctuation]\n",
    "print('\\nWORD LIST AFTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Character Punctuation Cleaning\n",
    "word_list = [''.join(char for char in word if char not in string.punctuation) for word in word_list]\n",
    "print('\\nWORD LIST AFTER CHARACTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Clean Stop Words\n",
    "stop_words = [\"and\", \"with\", \"using\", \"##\", \"working\", \"in\", \"to\"]\n",
    "word_list = [word for word in word_list if word not in stop_words]\n",
    "print('\\nWORD LIST AFTER STOP WORDS')\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code below creates a new dictionary from the words in the word_list. Using .fromkeys uses the words in the word_list to be the keys for the dictionary.\n",
    "\n",
    "Next, the program loops through the word_list and counts each word.\n",
    "\n",
    "The counter counts every word also and then is compared to the counts in the word_list to make sure all words were counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Top 10 Words\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# Resume Word Count\n",
    "# ==========================\n",
    "# Initialize a dictionary with default values equal to zero\n",
    "word_count = {}.fromkeys(word_list, 0)\n",
    "\n",
    "# Loop through the word list and count each word.\n",
    "for word in word_list:\n",
    "    word_count[word] += 1\n",
    "# print(word_count)\n",
    "\n",
    "# Bonus using collections.Counter\n",
    "word_counter = Counter(word_list)\n",
    "# print(word_counter)\n",
    "\n",
    "# Comparing both word count solutions\n",
    "print(word_count == word_counter)\n",
    "\n",
    "# Top 10 Words\n",
    "print(\"Top 10 Words\")\n",
    "print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell reads through the word count dictionary and sorts the list by the word_count (key vaues) in descending order (reverse = True) and returns the first 10 keys (key lables) from the sort. (the [:10] returns the first 10 items).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: data                 Count: 7\n",
      "Token:                      Count: 4\n",
      "Token: python               Count: 4\n",
      "Token: analytics            Count: 3\n",
      "Token: visualization        Count: 2\n",
      "Token: scripts              Count: 2\n",
      "Token: excel                Count: 2\n",
      "Token: statistics           Count: 2\n",
      "Token: social               Count: 2\n",
      "Token: media                Count: 2\n"
     ]
    }
   ],
   "source": [
    "# Sort words by count and print the top 10\n",
    "sorted_words = []\n",
    "for word in sorted(word_count, key=word_count.get, reverse=True)[:10]:\n",
    "    print(f\"Token: {word:20} Count: {word_count[word]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
